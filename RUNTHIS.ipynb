{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đồ án cuối kỳ - Phân tích chủ đề văn bản\n",
    "(Cập nhật 07/01/2021)\n",
    "\n",
    "Nhóm: 12\n",
    "\n",
    "Thành viên nhóm:\n",
    "- Vũ Đăng Hoàng Long - MSSV: 18120203\n",
    "- Nguyễn Huỳnh Đại Lợi - MSSV: 18120198"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/vlozg/.local/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/vlozg/.local/lib/python3.8/site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/vlozg/.local/lib/python3.8/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/vlozg/.local/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "Requirement already satisfied: tqdm in /home/vlozg/.local/lib/python3.8/site-packages (4.56.0)\n",
      "Requirement already satisfied: bs4 in /home/vlozg/.local/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/vlozg/.local/lib/python3.8/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/vlozg/.local/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.1)\n",
      "Requirement already up-to-date: scikit-learn in /home/vlozg/.local/lib/python3.8/site-packages (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /home/vlozg/.local/lib/python3.8/site-packages (from scikit-learn) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /home/vlozg/.local/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /home/vlozg/.local/lib/python3.8/site-packages (from scikit-learn) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /home/vlozg/.local/lib/python3.8/site-packages (from scikit-learn) (1.6.0)\n",
      "Requirement already satisfied: regex in /home/vlozg/.local/lib/python3.8/site-packages (2020.11.13)\n",
      "Requirement already satisfied: numpy in /home/vlozg/.local/lib/python3.8/site-packages (1.19.5)\n",
      "Requirement already satisfied: pyvi in /home/vlozg/.local/lib/python3.8/site-packages (0.1)\n",
      "Requirement already satisfied: sklearn-crfsuite in /home/vlozg/.local/lib/python3.8/site-packages (from pyvi) (0.3.6)\n",
      "Requirement already satisfied: scikit-learn in /home/vlozg/.local/lib/python3.8/site-packages (from pyvi) (0.24.0)\n",
      "Requirement already satisfied: tabulate in /home/vlozg/.local/lib/python3.8/site-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /home/vlozg/.local/lib/python3.8/site-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
      "Requirement already satisfied: tqdm>=2.0 in /home/vlozg/.local/lib/python3.8/site-packages (from sklearn-crfsuite->pyvi) (4.56.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sklearn-crfsuite->pyvi) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/vlozg/.local/lib/python3.8/site-packages (from scikit-learn->pyvi) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/vlozg/.local/lib/python3.8/site-packages (from scikit-learn->pyvi) (1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/vlozg/.local/lib/python3.8/site-packages (from scikit-learn->pyvi) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/vlozg/.local/lib/python3.8/site-packages (from scikit-learn->pyvi) (1.19.5)\n",
      "Requirement already satisfied: gensim in /home/vlozg/.local/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/vlozg/.local/lib/python3.8/site-packages (from gensim) (4.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/vlozg/.local/lib/python3.8/site-packages (from gensim) (1.6.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/lib/python3/dist-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/vlozg/.local/lib/python3.8/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: underthesea in /home/vlozg/.local/lib/python3.8/site-packages (1.3.1)\n",
      "Requirement already satisfied: nltk in /home/vlozg/.local/lib/python3.8/site-packages (from underthesea) (3.5)\n",
      "Requirement already satisfied: joblib in /home/vlozg/.local/lib/python3.8/site-packages (from underthesea) (1.0.0)\n",
      "Requirement already satisfied: unidecode in /home/vlozg/.local/lib/python3.8/site-packages (from underthesea) (1.1.2)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in /home/vlozg/.local/lib/python3.8/site-packages (from underthesea) (0.9.7)\n",
      "Requirement already satisfied: Click>=6.0 in /usr/lib/python3/dist-packages (from underthesea) (7.0)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from underthesea) (5.3.1)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from underthesea) (2.22.0)\n",
      "Requirement already satisfied: torch<=1.5.1,>=1.1.0 in /home/vlozg/.local/lib/python3.8/site-packages (from underthesea) (1.5.1)\n",
      "Requirement already satisfied: tqdm in /home/vlozg/.local/lib/python3.8/site-packages (from underthesea) (4.56.0)\n",
      "Requirement already satisfied: transformers<=3.5.1,>=3.5.0 in /home/vlozg/.local/lib/python3.8/site-packages (from underthesea) (3.5.1)\n",
      "Requirement already satisfied: scikit-learn in /home/vlozg/.local/lib/python3.8/site-packages (from underthesea) (0.24.0)\n",
      "Requirement already satisfied: seqeval in /home/vlozg/.local/lib/python3.8/site-packages (from underthesea) (1.2.2)\n",
      "Requirement already satisfied: regex in /home/vlozg/.local/lib/python3.8/site-packages (from nltk->underthesea) (2020.11.13)\n",
      "Requirement already satisfied: future in /home/vlozg/.local/lib/python3.8/site-packages (from torch<=1.5.1,>=1.1.0->underthesea) (0.18.2)\n",
      "Requirement already satisfied: numpy in /home/vlozg/.local/lib/python3.8/site-packages (from torch<=1.5.1,>=1.1.0->underthesea) (1.19.5)\n",
      "Requirement already satisfied: filelock in /home/vlozg/.local/lib/python3.8/site-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /home/vlozg/.local/lib/python3.8/site-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.0.43)\n",
      "Requirement already satisfied: packaging in /home/vlozg/.local/lib/python3.8/site-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (20.8)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in /home/vlozg/.local/lib/python3.8/site-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.9.3)\n",
      "Requirement already satisfied: protobuf in /home/vlozg/.local/lib/python3.8/site-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.14.0)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in /home/vlozg/.local/lib/python3.8/site-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.1.91)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/vlozg/.local/lib/python3.8/site-packages (from scikit-learn->underthesea) (1.6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/vlozg/.local/lib/python3.8/site-packages (from scikit-learn->underthesea) (2.1.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers<=3.5.1,>=3.5.0->underthesea) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/vlozg/.local/lib/python3.8/site-packages (from packaging->transformers<=3.5.1,>=3.5.0->underthesea) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install tqdm\n",
    "!pip3 install bs4\n",
    "!pip3 install -U scikit-learn\n",
    "!pip3 install regex\n",
    "!pip3 install numpy\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import time # Dùng để sleep chương trình\n",
    "from tqdm.notebook import tqdm # Hiện thanh progress cho đẹp :D\n",
    "\n",
    "# Thư viện để lấy và parse HTML\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Các thư viện liên quan tới ngôn ngữ và NLP\n",
    "!pip3 install pyvi ;\n",
    "!pip3 install gensim ;\n",
    "!pip3 install underthesea ;\n",
    "from pyvi import ViTokenizer # thư viện NLP tiếng Việt\n",
    "from underthesea import word_tokenize\n",
    "import gensim\n",
    "import unicodedata\n",
    "\n",
    "# Thư viện liên quan đến machine learning của Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler,LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_4 = \"src/scraped_data/\"\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import toàn bộ data (không khuyến cáo nếu máy không nhiều ram)\n",
    "df = []\n",
    "for i in range(218):\n",
    "    df.append(pd.read_csv(dir_4 + f'crawling_{i}.csv'))\n",
    "    \n",
    "data_df=pd.concat(df)\n",
    "data_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(['links', 'title', 'description'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_preprocess(df):\n",
    "    selected_class = [\"xã hội\", \"thế giới\", \"thể thao\", \"kinh doanh\", \"văn hóa\", \"pháp luật\", \"sức khỏe\", \"nhịp sống trẻ\",\n",
    "                      \"giáo dục\", \"thời sự\", \"nhịp sống số\", \"tuyển sinh\", \"du lịch\", \"phóng sự\", \"nhà đất\", \"yêu\",\n",
    "                      \"điện ảnh\", \"tài chính\", \"âm nhạc\", \"khoa học\", \"giải trí\", \"tv show\", \"công nghệ\", \"xe\",\n",
    "                      \"thời trang\", \"smarthome\", \"đi chơi\", \"câu chuyện giáo dục\", \"hồ sơ\", \"thời sự quốc tế\", \"ăn gì\"]\n",
    "    processed_df = df[df[\"class\"].isin(selected_class)].copy()\n",
    "    processed_df.loc[processed_df[\"class\"].isin([\"thế giới\", \"hồ sơ\"]), \"class\"] = \"thời sự quốc tế\"\n",
    "    processed_df.loc[processed_df[\"class\"].isin([\"xã hội\", \"thời sự\", \"phóng sự\"]), \"class\"] = \"thời sự trong nước\"\n",
    "    processed_df.loc[processed_df[\"class\"] == \"đi chơi\", \"class\"] = \"du lịch\"\n",
    "    processed_df.loc[processed_df[\"class\"].isin([\"tài chính\", \"doanh nghiệp\"]), \"class\"] = \"kinh doanh\"\n",
    "    processed_df.loc[processed_df[\"class\"] == \"nhịp sống số\", \"class\"] = \"công nghệ\"\n",
    "    processed_df.loc[processed_df[\"class\"].isin([\"âm nhạc\", \"tv show\", \"điện ảnh\"]), \"class\"] = \"giải trí\"\n",
    "    processed_df.loc[processed_df[\"class\"] == \"smarthome\", \"class\"] = \"nhà đất\"\n",
    "    processed_df.loc[processed_df[\"class\"].isin([\"phòng mạch\", \"biết để khỏe\"]), \"class\"] = \"sức khỏe\"\n",
    "    processed_df.loc[processed_df[\"class\"].isin([\"tuyển sinh\", \"học đường\", \"câu chuyện giáo dục\"]), \"class\"] = \"giáo dục\"\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thời sự trong nước    142809\n",
       "thời sự quốc tế        80010\n",
       "thể thao               69875\n",
       "kinh doanh             60805\n",
       "văn hóa                43199\n",
       "giáo dục               41822\n",
       "nhịp sống trẻ          40813\n",
       "pháp luật              38785\n",
       "sức khỏe               30409\n",
       "giải trí               24718\n",
       "công nghệ              20825\n",
       "du lịch                13208\n",
       "nhà đất                10639\n",
       "yêu                     8922\n",
       "khoa học                6078\n",
       "xe                      2823\n",
       "ăn gì                   2286\n",
       "thời trang              1605\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_preprocess(data_df)[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = class_preprocess(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandarallel in /home/vlozg/.local/lib/python3.8/site-packages (1.5.1)\n",
      "Requirement already satisfied: dill in /home/vlozg/.local/lib/python3.8/site-packages (from pandarallel) (0.3.3)\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandarallel\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 5.64 s, total: 19 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#xoá ký tự thừa\n",
    "def remove_unnecessary(paragraph):\n",
    "    temp=re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',paragraph)\n",
    "    return re.sub(r'\\s+', ' ', temp).strip()\n",
    "\n",
    "data_df['content']=data_df['content'].parallel_apply(remove_unnecessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tqdm.pandas()\n",
    "#data_df['content']=data_df['content'].parallel_apply(ViTokenizer.tokenize)\n",
    "data_df['content']=data_df['content'].parallel_apply(lambda x: word_tokenize(x, format=\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('src/vietnamese-stopwords-dash.txt', encoding='utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "# Danh sách stopword\n",
    "stopword = set(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(line):\n",
    "    words = []\n",
    "    for word in line.strip().split():\n",
    "        if word not in stopword:\n",
    "            words.append(word)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_df['content']=data_df['content'].parallel_apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tạo pipe tiền xử lý cho đoạn văn bản bất kỳ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tách tập train, tập test và tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sr = data_df[\"class\"] # sr là viết tắt của series\n",
    "X_df = data_df[\"content\"]\n",
    "train_X_df, val_X_df, train_y_sr, val_y_sr = train_test_split(X_df, y_sr, test_size=0.3,stratify=y_sr, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering đưa dữ liệu dạng văn bản đã được xử lý về dạng vector thuộc tính có dạng số học bằng TF-IDF Vectors ở mức Word level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level - we choose max number of words equal to 30000 except all words (100k+ words)\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_features=30000)\n",
    "tfidf_vect.fit(train_X_df) # learn vocabulary and idf from training set\n",
    "train_X_tfidf =  tfidf_vect.transform(train_X_df)\n",
    "# assume that we don't have test set before\n",
    "val_X_tfidf =  tfidf_vect.transform(val_X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "svd.fit(train_X_tfidf)\n",
    "\n",
    "\n",
    "train_X_tfidf_svd = svd.transform(train_X_tfidf)\n",
    "val_X_tfidf_svd = svd.transform(val_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tfidf_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder =LabelEncoder()\n",
    "train_y_sr_n = encoder.fit_transform(train_y_sr)\n",
    "val_y_sr_n = encoder.fit_transform(val_y_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg_model=LogisticRegression()\n",
    "log_reg_model.fit(train_X_tfidf_svd,train_y_sr_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Độ chính xác tập training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model.score(train_X_tfidf_svd,train_y_sr_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Độ chính xác tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=log_reg_model.predict(val_X_tfidf_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (prediction != val_y_sr_n).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_classifier=SVC()\n",
    "svm_classifier.fit(train_X_tfidf_svd,train_y_sr_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Độ chính xác tập training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier.score(train_X_tfidf_svd,train_y_sr_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Độ chính xác tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=svm_classifier.predict(val_X_tfidf_svd)\n",
    "1 - (prediction != val_y_sr_n).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier=MLPClassifier(hidden_layer_sizes=(20), activation='tanh',\n",
    "                                 solver='lbfgs', random_state=0, max_iter=2500)\n",
    "mlp_classifier.fit(train_X_tfidf_svd,train_y_sr_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Độ chính xác tập training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier.score(train_X_tfidf_svd,train_y_sr_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Độ chính xác tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=mlp_classifier.predict(val_X_tfidf_svd)\n",
    "1 - (prediction != val_y_sr_n).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "306.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
