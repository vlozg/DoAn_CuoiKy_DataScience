{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time # Dùng để sleep chương trình\n",
    "import pandas as pd # Dùng để đọc và hiển thị file csv (Pandas sẽ được học chi tiết ở buổi tới)\n",
    "import datetime as dt # Dùng để xử lý dữ liệu thời gian\n",
    "import re\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('Chrome_driver\\chromedriver')\n",
    "driver.get(\"https://tuoitre.vn/tin-moi-nhat.htm\")\n",
    "button = driver.find_element_by_class_name('btn-readmore')\n",
    "for x in range(100):\n",
    "    time.sleep(3)\n",
    "    button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "element=driver.find_element_by_class_name('list-news-content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup = BeautifulSoup(element.get_attribute('innerHTML'), 'html.parser')\n",
    "titles = soup.findAll('h3', class_='title-news')\n",
    "links = [link.find('a').attrs[\"href\"] for link in titles]\n",
    "category=soup.findAll('a', class_='category-name fl mgl10 mgb4 uppercase')\n",
    "category_column=[]\n",
    "for x in category:\n",
    "    category_column+=[x.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test new version by Long\n",
    "url = \"https://tuoitre.vn/timeline/0/trang-1.htm\"\n",
    "html_text = requests.get(url).text\n",
    "#Code below is just copy from above\n",
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "titles = soup.findAll('h3', class_='title-news')\n",
    "links = [link.find('a').attrs[\"href\"] for link in titles]\n",
    "category=soup.findAll('a', class_='category-name fl mgl10 mgb4 uppercase')\n",
    "category_column=[]\n",
    "for x in category:\n",
    "    category_column+=[x.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def links_scraping(iter_num, num, sleep_time = 1):\n",
    "    continue_flag = True\n",
    "    links = []\n",
    "    category_column=[]\n",
    "\n",
    "    for index in range(iter_num*num+1,(iter_num+1)*num+1):\n",
    "        url = f\"https://tuoitre.vn/timeline/0/trang-{index}.htm\"\n",
    "        html_text = requests.get(url).text\n",
    "        \n",
    "        soup = BeautifulSoup(html_text, 'html.parser')\n",
    "        #Get links\n",
    "        try:\n",
    "            titles = soup.findAll('h3', class_='title-news')\n",
    "        except:\n",
    "            continue_flag = False\n",
    "            continue\n",
    "        links+=[link.find('a').attrs[\"href\"] for link in titles]\n",
    "        #Get categories\n",
    "        try:\n",
    "            category=soup.findAll('a', class_='category-name')\n",
    "        except:\n",
    "            continue_flag = False\n",
    "            continue\n",
    "        for x in category:\n",
    "            category_column+=[x.text]\n",
    "        #Sleep\n",
    "        if (index%10==0): print(f\"Page {index} complete!\")\n",
    "        time.sleep(sleep_time)\n",
    "    return (links,category_column,continue_flag)\n",
    "\n",
    "def content_scraping(links, sleep_time = 1):\n",
    "    title_column=[]\n",
    "    description_column=[]\n",
    "    content_column=[]\n",
    "    for link in links:\n",
    "        news = requests.get(\"https://tuoitre.vn\" + link)\n",
    "        soup= BeautifulSoup(news.content, \"html.parser\")\n",
    "        try:\n",
    "            title=soup.find(\"h1\", class_=\"article-title\").text\n",
    "        except:\n",
    "            title=''\n",
    "        title_column+=[title]\n",
    "        try:\n",
    "            description=soup.find(\"h2\", class_=\"sapo\").text\n",
    "        except:\n",
    "            description=''\n",
    "        description_column+=[description]\n",
    "        body = soup.find(\"div\", id=\"main-detail-body\")\n",
    "        try:\n",
    "            content=body.findChildren(\"p\", recursive=False)\n",
    "            contents=''\n",
    "            for x in content:\n",
    "                contents+=x.text\n",
    "        except:\n",
    "            contents=''\n",
    "        content_column+=[contents]\n",
    "        time.sleep(sleep_time)\n",
    "    return (title_column,description_column,content_column)\n",
    "\n",
    "def export_scraped(links,title_column,description_column,content_column,category_column,batch_num):\n",
    "    #Convert scraped data -> data frame\n",
    "    df=pd.DataFrame()\n",
    "    df['links']=links\n",
    "    df['title']=title_column\n",
    "    df['description']=description_column\n",
    "    df['content']=content_column\n",
    "    df['class']=category_column\n",
    "    #Export for future use\n",
    "    df.to_csv(f'scraped_data\\crawling_{batch_num}.csv',index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 2410 complete!\n",
      "Page 2420 complete!\n",
      "Page 2430 complete!\n",
      "Page 2440 complete!\n",
      "Page 2450 complete!\n",
      "Page 2460 complete!\n",
      "Page 2470 complete!\n",
      "Page 2480 complete!\n",
      "Page 2490 complete!\n",
      "Page 2500 complete!\n",
      "Page 2510 complete!\n",
      "Page 2520 complete!\n",
      "Page 2530 complete!\n",
      "Page 2540 complete!\n",
      "Page 2550 complete!\n",
      "Page 2560 complete!\n",
      "Page 2570 complete!\n",
      "Page 2580 complete!\n",
      "Page 2590 complete!\n",
      "Page 2600 complete!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (3979) does not match length of index (3980)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-dc9d618335ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlinks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategory_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontinue_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinks_scraping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtitle_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdescription_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontent_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontent_scraping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mexport_scraped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtitle_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdescription_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontent_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategory_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0miter_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mcontinue_flag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0miter_num\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-a5cf18385696>\u001b[0m in \u001b[0;36mexport_scraped\u001b[1;34m(links, title_column, description_column, content_column, category_column, batch_num)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdescription_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontent_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategory_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;31m#Export for future use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'scraped_data\\crawling_{batch_num}.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3039\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3040\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3114\u001b[0m         \"\"\"\n\u001b[0;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3760\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3761\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3762\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3763\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \"\"\"\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    748\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (3979) does not match length of index (3980)"
     ]
    }
   ],
   "source": [
    "#Batch scraping\n",
    "iter_num = 12\n",
    "continue_flag = True\n",
    "\n",
    "while (continue_flag):\n",
    "    links,category_column,continue_flag = links_scraping(iter_num, 200,0)\n",
    "    title_column,description_column,content_column = content_scraping(links,0)\n",
    "    export_scraped(links,title_column,description_column,content_column,category_column,iter_num)\n",
    "    if (not continue_flag): break\n",
    "    else: iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_column=[]\n",
    "description_column=[]\n",
    "content_column=[]\n",
    "for link in links:\n",
    "    news = requests.get(\"https://tuoitre.vn\" + link)\n",
    "    soup= BeautifulSoup(news.content, \"html.parser\")\n",
    "    try:\n",
    "        title=soup.find(\"h1\", class_=\"article-title\").text\n",
    "    except:\n",
    "        title=''\n",
    "    title_column+=[title]\n",
    "    try:\n",
    "        description=soup.find(\"h2\", class_=\"sapo\").text\n",
    "    except:\n",
    "        description=''\n",
    "    description_column+=[description]\n",
    "    body = soup.find(\"div\", id=\"main-detail-body\")\n",
    "    try:\n",
    "        content=body.findChildren(\"p\", recursive=False)\n",
    "        contents=''\n",
    "        for x in content:\n",
    "            contents+=x.text\n",
    "    except:\n",
    "        contents=''\n",
    "    content_column+=[contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/nhu-chua-he-co-cuoc-chia-ly-gap-mat-con-mot-l...</td>\n",
       "      <td>Như chưa hề có cuộc chia ly: ‘Gặp mặt con một ...</td>\n",
       "      <td>TTO - Sau 51 năm đi khắp nơi tìm kiếm con trai...</td>\n",
       "      <td>Đây là một trong số những trường hợp trẻ em th...</td>\n",
       "      <td>Giải trí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/hai-nu-sinh-bi-danh-hoi-dong-tren-pho-phong-g...</td>\n",
       "      <td>Hai nữ sinh bị đánh hội đồng trên phố, Phòng G...</td>\n",
       "      <td>TTO - Ngày 4-1, Phòng Giáo dục và đào tạo quận...</td>\n",
       "      <td>Theo thông tin xác nhận từ Phòng Giáo dục và đ...</td>\n",
       "      <td>Giáo dục</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/diem-tin-the-thao-toi-4-1-cuu-gdkt-bong-da-nh...</td>\n",
       "      <td>Điểm tin thể thao tối 4-1: Cựu GĐKT bóng đa...</td>\n",
       "      <td>TTO - CLB Sài Gòn có cố vấn cấp cao \"xịn\", CLB...</td>\n",
       "      <td>Cựu GĐKT bóng đá Nhật Bản làm cố vâ...</td>\n",
       "      <td>Thể thao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/iran-bat-tau-cho-hoa-chat-han-quoc-co-thuyen-...</td>\n",
       "      <td>Iran bắt tàu chở hóa chất Hàn Quốc có thuyền v...</td>\n",
       "      <td>TTO - Truyền thông Iran ngày 4-1 cho biết Vệ b...</td>\n",
       "      <td>Một số hãng truyền thông Iran cho biết IRGC đã...</td>\n",
       "      <td>Thế giới</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/canh-bao-chieu-muon-danh-ngan-hang-moi-du-hoi...</td>\n",
       "      <td>Cảnh báo chiêu mượn danh ngân hàng mời dự hội ...</td>\n",
       "      <td>TTO - Giả danh ngân hàng gọi điện thoại mời mở...</td>\n",
       "      <td>VPBank vừa phát đi cảnh báo trên vào hôm nay, ...</td>\n",
       "      <td>Kinh doanh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               links  \\\n",
       "0  /nhu-chua-he-co-cuoc-chia-ly-gap-mat-con-mot-l...   \n",
       "1  /hai-nu-sinh-bi-danh-hoi-dong-tren-pho-phong-g...   \n",
       "2  /diem-tin-the-thao-toi-4-1-cuu-gdkt-bong-da-nh...   \n",
       "3  /iran-bat-tau-cho-hoa-chat-han-quoc-co-thuyen-...   \n",
       "4  /canh-bao-chieu-muon-danh-ngan-hang-moi-du-hoi...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Như chưa hề có cuộc chia ly: ‘Gặp mặt con một ...   \n",
       "1  Hai nữ sinh bị đánh hội đồng trên phố, Phòng G...   \n",
       "2  Điểm tin thể thao tối 4-1: Cựu GĐKT bóng đa...   \n",
       "3  Iran bắt tàu chở hóa chất Hàn Quốc có thuyền v...   \n",
       "4  Cảnh báo chiêu mượn danh ngân hàng mời dự hội ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  TTO - Sau 51 năm đi khắp nơi tìm kiếm con trai...   \n",
       "1  TTO - Ngày 4-1, Phòng Giáo dục và đào tạo quận...   \n",
       "2  TTO - CLB Sài Gòn có cố vấn cấp cao \"xịn\", CLB...   \n",
       "3  TTO - Truyền thông Iran ngày 4-1 cho biết Vệ b...   \n",
       "4  TTO - Giả danh ngân hàng gọi điện thoại mời mở...   \n",
       "\n",
       "                                             content       class  \n",
       "0  Đây là một trong số những trường hợp trẻ em th...    Giải trí  \n",
       "1  Theo thông tin xác nhận từ Phòng Giáo dục và đ...    Giáo dục  \n",
       "2  Cựu GĐKT bóng đá Nhật Bản làm cố vâ...    Thể thao  \n",
       "3  Một số hãng truyền thông Iran cho biết IRGC đã...    Thế giới  \n",
       "4  VPBank vừa phát đi cảnh báo trên vào hôm nay, ...  Kinh doanh  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert scraped data -> data frame\n",
    "df=pd.DataFrame()\n",
    "df['links']=links\n",
    "df['title']=title_column\n",
    "df['description']=description_column\n",
    "df['content']=content_column\n",
    "df['class']=category_column\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export for future use\n",
    "df.to_csv('crawling.csv',index=False,encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
