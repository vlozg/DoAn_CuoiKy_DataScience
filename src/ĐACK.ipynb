{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time # Dùng để sleep chương trình\n",
    "import pandas as pd # Dùng để đọc và hiển thị file csv (Pandas sẽ được học chi tiết ở buổi tới)\n",
    "import datetime as dt # Dùng để xử lý dữ liệu thời gian\n",
    "import re\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('Chrome_driver\\chromedriver')\n",
    "driver.get(\"https://tuoitre.vn/tin-moi-nhat.htm\")\n",
    "button = driver.find_element_by_class_name('btn-readmore')\n",
    "for x in range(100):\n",
    "    time.sleep(3)\n",
    "    button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "element=driver.find_element_by_class_name('list-news-content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup = BeautifulSoup(element.get_attribute('innerHTML'), 'html.parser')\n",
    "titles = soup.findAll('h3', class_='title-news')\n",
    "links = [link.find('a').attrs[\"href\"] for link in titles]\n",
    "category=soup.findAll('a', class_='category-name fl mgl10 mgb4 uppercase')\n",
    "category_column=[]\n",
    "for x in category:\n",
    "    category_column+=[x.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test new version by Long\n",
    "url = \"https://tuoitre.vn/timeline/0/trang-1.htm\"\n",
    "html_text = requests.get(url).text\n",
    "#Code below is just copy from above\n",
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "titles = soup.findAll('h3', class_='title-news')\n",
    "links = [link.find('a').attrs[\"href\"] for link in titles]\n",
    "category=soup.findAll('a', class_='category-name fl mgl10 mgb4 uppercase')\n",
    "category_column=[]\n",
    "for x in category:\n",
    "    category_column+=[x.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def links_scraping(iter_num, num, sleep_time = 1):\n",
    "    continue_flag = True\n",
    "    links = []\n",
    "    category_column=[]\n",
    "\n",
    "    for index in range(iter_num*num+1,(iter_num+1)*num+1):\n",
    "        url = f\"https://tuoitre.vn/timeline/0/trang-{index}.htm\"\n",
    "        html_text = requests.get(url).text\n",
    "\n",
    "        soup = BeautifulSoup(html_text, 'html.parser')\n",
    "        #Get links\n",
    "        try:\n",
    "            titles = soup.findAll('h3', class_='title-news')\n",
    "        except:\n",
    "            continue_flag = False\n",
    "            continue\n",
    "        links+=[link.find('a').attrs[\"href\"] for link in titles]\n",
    "        #Get categories\n",
    "        try:\n",
    "            category=soup.findAll('a', class_='category-name fl mgl10 mgb4 uppercase')\n",
    "        except:\n",
    "            continue_flag = False\n",
    "            continue\n",
    "        for x in category:\n",
    "            category_column+=[x.text]\n",
    "        #Sleep\n",
    "        if (index%10==0): print(f\"Page {index} complete!\")\n",
    "        time.sleep(sleep_time)\n",
    "    return (links,category_column,continue_flag)\n",
    "\n",
    "def content_scraping(links):\n",
    "    title_column=[]\n",
    "    description_column=[]\n",
    "    content_column=[]\n",
    "    for link in links:\n",
    "        news = requests.get(\"https://tuoitre.vn\" + link)\n",
    "        soup= BeautifulSoup(news.content, \"html.parser\")\n",
    "        try:\n",
    "            title=soup.find(\"h1\", class_=\"article-title\").text\n",
    "        except:\n",
    "            title=''\n",
    "        title_column+=[title]\n",
    "        try:\n",
    "            description=soup.find(\"h2\", class_=\"sapo\").text\n",
    "        except:\n",
    "            description=''\n",
    "        description_column+=[description]\n",
    "        body = soup.find(\"div\", id=\"main-detail-body\")\n",
    "        try:\n",
    "            content=body.findChildren(\"p\", recursive=False)\n",
    "            contents=''\n",
    "            for x in content:\n",
    "                contents+=x.text\n",
    "        except:\n",
    "            contents=''\n",
    "        content_column+=[contents]\n",
    "    return (title_column,description_column,content_column)\n",
    "\n",
    "def export(title_column,description_column,content_column,category_column,batch_num):\n",
    "    #Convert scraped data -> data frame\n",
    "    df=pd.DataFrame()\n",
    "    df['links']=links\n",
    "    df['title']=title_column\n",
    "    df['description']=description_column\n",
    "    df['content']=content_column\n",
    "    df['class']=category_column\n",
    "    #Export for future use\n",
    "    df.to_csv(f'scraped_data\\crawling_{batch_num}.csv',index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 10 complete!\n",
      "Page 20 complete!\n",
      "Page 30 complete!\n",
      "Page 40 complete!\n",
      "Page 50 complete!\n",
      "Page 60 complete!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4d86c610b525>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcontinue_flag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mlinks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategory_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontinue_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinks_scraping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtitle_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdescription_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontent_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontent_scraping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdescription_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontent_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategory_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0miter_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-1a73d263f242>\u001b[0m in \u001b[0;36mlinks_scraping\u001b[1;34m(iter_num, num, sleep_time)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m#Sleep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Page {index} complete!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msleep_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategory_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontinue_flag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Batch scraping\n",
    "iter_num = 0\n",
    "continue_flag = True\n",
    "\n",
    "while (continue_flag):\n",
    "    links,category_column,continue_flag = links_scraping(iter_num, 200)\n",
    "    title_column,description_column,content_column = content_scraping(links)\n",
    "    export(title_column,description_column,content_column,category_column,iter_num)\n",
    "    if (not continue_flag): break\n",
    "    else: inter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_column=[]\n",
    "description_column=[]\n",
    "content_column=[]\n",
    "for link in links:\n",
    "    news = requests.get(\"https://tuoitre.vn\" + link)\n",
    "    soup= BeautifulSoup(news.content, \"html.parser\")\n",
    "    try:\n",
    "        title=soup.find(\"h1\", class_=\"article-title\").text\n",
    "    except:\n",
    "        title=''\n",
    "    title_column+=[title]\n",
    "    try:\n",
    "        description=soup.find(\"h2\", class_=\"sapo\").text\n",
    "    except:\n",
    "        description=''\n",
    "    description_column+=[description]\n",
    "    body = soup.find(\"div\", id=\"main-detail-body\")\n",
    "    try:\n",
    "        content=body.findChildren(\"p\", recursive=False)\n",
    "        contents=''\n",
    "        for x in content:\n",
    "            contents+=x.text\n",
    "    except:\n",
    "        contents=''\n",
    "    content_column+=[contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/nhu-chua-he-co-cuoc-chia-ly-gap-mat-con-mot-l...</td>\n",
       "      <td>Như chưa hề có cuộc chia ly: ‘Gặp mặt con một ...</td>\n",
       "      <td>TTO - Sau 51 năm đi khắp nơi tìm kiếm con trai...</td>\n",
       "      <td>Đây là một trong số những trường hợp trẻ em th...</td>\n",
       "      <td>Giải trí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/hai-nu-sinh-bi-danh-hoi-dong-tren-pho-phong-g...</td>\n",
       "      <td>Hai nữ sinh bị đánh hội đồng trên phố, Phòng G...</td>\n",
       "      <td>TTO - Ngày 4-1, Phòng Giáo dục và đào tạo quận...</td>\n",
       "      <td>Theo thông tin xác nhận từ Phòng Giáo dục và đ...</td>\n",
       "      <td>Giáo dục</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/diem-tin-the-thao-toi-4-1-cuu-gdkt-bong-da-nh...</td>\n",
       "      <td>Điểm tin thể thao tối 4-1: Cựu GĐKT bóng đa...</td>\n",
       "      <td>TTO - CLB Sài Gòn có cố vấn cấp cao \"xịn\", CLB...</td>\n",
       "      <td>Cựu GĐKT bóng đá Nhật Bản làm cố vâ...</td>\n",
       "      <td>Thể thao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/iran-bat-tau-cho-hoa-chat-han-quoc-co-thuyen-...</td>\n",
       "      <td>Iran bắt tàu chở hóa chất Hàn Quốc có thuyền v...</td>\n",
       "      <td>TTO - Truyền thông Iran ngày 4-1 cho biết Vệ b...</td>\n",
       "      <td>Một số hãng truyền thông Iran cho biết IRGC đã...</td>\n",
       "      <td>Thế giới</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/canh-bao-chieu-muon-danh-ngan-hang-moi-du-hoi...</td>\n",
       "      <td>Cảnh báo chiêu mượn danh ngân hàng mời dự hội ...</td>\n",
       "      <td>TTO - Giả danh ngân hàng gọi điện thoại mời mở...</td>\n",
       "      <td>VPBank vừa phát đi cảnh báo trên vào hôm nay, ...</td>\n",
       "      <td>Kinh doanh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               links  \\\n",
       "0  /nhu-chua-he-co-cuoc-chia-ly-gap-mat-con-mot-l...   \n",
       "1  /hai-nu-sinh-bi-danh-hoi-dong-tren-pho-phong-g...   \n",
       "2  /diem-tin-the-thao-toi-4-1-cuu-gdkt-bong-da-nh...   \n",
       "3  /iran-bat-tau-cho-hoa-chat-han-quoc-co-thuyen-...   \n",
       "4  /canh-bao-chieu-muon-danh-ngan-hang-moi-du-hoi...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Như chưa hề có cuộc chia ly: ‘Gặp mặt con một ...   \n",
       "1  Hai nữ sinh bị đánh hội đồng trên phố, Phòng G...   \n",
       "2  Điểm tin thể thao tối 4-1: Cựu GĐKT bóng đa...   \n",
       "3  Iran bắt tàu chở hóa chất Hàn Quốc có thuyền v...   \n",
       "4  Cảnh báo chiêu mượn danh ngân hàng mời dự hội ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  TTO - Sau 51 năm đi khắp nơi tìm kiếm con trai...   \n",
       "1  TTO - Ngày 4-1, Phòng Giáo dục và đào tạo quận...   \n",
       "2  TTO - CLB Sài Gòn có cố vấn cấp cao \"xịn\", CLB...   \n",
       "3  TTO - Truyền thông Iran ngày 4-1 cho biết Vệ b...   \n",
       "4  TTO - Giả danh ngân hàng gọi điện thoại mời mở...   \n",
       "\n",
       "                                             content       class  \n",
       "0  Đây là một trong số những trường hợp trẻ em th...    Giải trí  \n",
       "1  Theo thông tin xác nhận từ Phòng Giáo dục và đ...    Giáo dục  \n",
       "2  Cựu GĐKT bóng đá Nhật Bản làm cố vâ...    Thể thao  \n",
       "3  Một số hãng truyền thông Iran cho biết IRGC đã...    Thế giới  \n",
       "4  VPBank vừa phát đi cảnh báo trên vào hôm nay, ...  Kinh doanh  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert scraped data -> data frame\n",
    "df=pd.DataFrame()\n",
    "df['links']=links\n",
    "df['title']=title_column\n",
    "df['description']=description_column\n",
    "df['content']=content_column\n",
    "df['class']=category_column\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export for future use\n",
    "df.to_csv('crawling.csv',index=False,encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
